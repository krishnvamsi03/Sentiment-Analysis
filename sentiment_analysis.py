# -*- coding: utf-8 -*-
"""sentiment_analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_e-GfuC_eH2mwDv0-vYwMgNmJ7_TLaaM
"""

import nltk
nltk.download('stopwords')

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import nltk
import re
from nltk.corpus import stopwords
from nltk.stem.porter import PorterStemmer

dataset = pd.read_csv('Tweets.csv')

dataset.head()

dataset['airline'].value_counts().plot.bar()

sentiments_X_airlines = pd.crosstab(dataset['airline'], dataset['airline_sentiment'])
sentiments_X_airlines.plot.bar()

X = dataset.iloc[:, 10].values

def processing(tweets):
  sentiments = []
  for i in range(len(tweets)):
      temp = re.sub('^[a-zA-Z]', ' ', tweets[i])
      temp = temp.lower()
      temp = temp.split()
      ps = PorterStemmer()
      temp = [ps.stem(word) for word in temp if word not in set(stopwords.words('english'))]
      temp = ' '.join(temp)
      sentiments.append(temp)
      
  return sentiments
    
sentiments = processing(X)

from sklearn.feature_extraction.text import CountVectorizer
cv = CountVectorizer(max_features = 2500, max_df = 0.8, min_df = 5)
X = cv.fit_transform(sentiments).toarray()

labels, unique = pd.factorize(dataset.iloc[:, 1])
y = np.array(labels)

X = X.astype(np.float32)
#y = y.astype(np.float32)

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)

X_train.shape

y_train.shape

import tensorflow as tf

def model(features, labels, mode):

  layer1 = tf.layers.dense(features, units = 512, activation = tf.nn.relu)
  layer2 = tf.layers.dense(layer1, units = 1024, activation = tf.nn.relu)
  layer3 = tf.layers.dense(layer2, units = 1024, activation = tf.nn.relu)
  
  output = tf.layers.dense(layer3, units = 3)

  probabilities = tf.nn.softmax(logits = output)
  classes = tf.argmax(tf.nn.softmax(logits = output), 1)
  
  if mode == tf.estimator.ModeKeys.PREDICT:
    return tf.estimator.EstimatorSpec(mode, predictions = classes)

  labels = tf.reshape(labels, [-1])
  loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits = output, labels = tf.cast(labels, dtype = tf.int64)), name = 'loss_fn')
  
  
  if mode == tf.estimator.ModeKeys.TRAIN:

    optimizer = tf.train.RMSPropOptimizer(0.03)
    train_op = optimizer.minimize(
        loss = loss,
        global_step = tf.train.get_global_step()
    )
    expo = {
        'acc' : tf.metrics.accuracy(labels = labels, predictions = classes, name = 'accuracy_fn')
    }
    
    return tf.estimator.EstimatorSpec(mode = mode, train_op = train_op, loss = loss, export_outputs = expo)
  
  eval_metrics_op = {
      'accuracy' : tf.metrics.accuracy(labels = labels, predictions = classes)
  }
  return tf.estimator.EstimatorSpec(mode = mode, eval_metric_ops = eval_metrics_op, loss = loss)

logging_hook = {
    'loss': 'loss_fn',
    
}

tensor_hook = tf.train.LoggingTensorHook(
    tensors = logging_hook, every_n_iter = 100
)

tf.logging.set_verbosity(tf.logging.INFO)

classifier = tf.estimator.Estimator(model_fn = model)

train_fn = tf.estimator.inputs.numpy_input_fn(
    x = X_train,
    y = np.matrix(y_train).T,
    num_epochs = None,
    batch_size = 100,
    shuffle = True,   
)

test_fn = tf.estimator.inputs.numpy_input_fn(
    x = X_test,
    y = np.matrix(y_test).T,
    num_epochs = 1,
    shuffle = False,
)

classifier.train(
    input_fn = train_fn,
    steps = 1000,
    hooks = [tensor_hook]
)

eval_ = classifier.evaluate(
    input_fn = test_fn,
    steps = 1,
)
print('Accuracy is {}'.format(eval_['accuracy']))